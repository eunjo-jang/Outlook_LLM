# rag_streamlit_chatbot.py
import os
import streamlit as st
from dotenv import load_dotenv
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.documents import Document
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_community.embeddings import HuggingFaceEmbeddings

# =====================
# 0. Load API key
# =====================
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found. Check your .env file or environment variable.")

# =====================
# 1. Streamlit UI Setup
# =====================
st.set_page_config(page_title="Outlook RAG Chatbot", layout="wide", initial_sidebar_state="collapsed")
st.title("ðŸ“§ ITER Outlook RAG Chatbot")
st.caption("ðŸ’¬ Ask questions about ITER Vacuum Vessel project emails")

# ì±„íŒ… ížˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "source_docs" not in st.session_state:
    st.session_state.source_docs = {}

# =====================
# 2. Load Vector DB
# =====================
CHROMA_PATH = "../data/vectorstore/chroma_outlook"
COLLECTION_NAME = "email_rag_collection"

embedding_model = HuggingFaceEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={"device": "cuda"}  # GPU ì‚¬ìš© (RTX 6000 Ada)
)

vectorstore = Chroma(
    persist_directory=CHROMA_PATH,
    collection_name=COLLECTION_NAME,
    embedding_function=embedding_model
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 10})  # Top 10 ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰

# =====================
# 3. Query Analysis & Filtering
# =====================
def extract_query_filters(query: str, llm) -> dict:
    """LLMìœ¼ë¡œ ì¿¼ë¦¬ì—ì„œ í•„í„° ì¡°ê±´ ì¶”ì¶œ"""
    filter_prompt = ChatPromptTemplate.from_messages([
        ("system", 
         "You are a query analyzer. Extract search filters from the user's question.\n"
         "Return ONLY a valid JSON object with these fields (use null if not found):\n"
         "{{\n"
         '  "date_exact": "YYYY-MM-DD" or null,\n'
         '  "date_month": "YYYY-MM" or null,\n'
         '  "date_year": "YYYY" or null,\n'
         '  "sender_name": "name" or null,\n'
         '  "keywords": ["keyword1", "keyword2"] or []\n'
         "}}\n\n"
         "Examples:\n"
         'Q: "What happened on January 31, 2021?" â†’ {{"date_exact": "2021-01-31", ...}}\n'
         'Q: "Emails in July 2021" â†’ {{"date_month": "2021-07", ...}}\n'
         'Q: "What did Alex Martin say?" â†’ {{"sender_name": "Alex Martin", ...}}\n'
         'Q: "ANB reports" â†’ {{"keywords": ["ANB", "report"], ...}}\n'),
        ("human", "Question: {question}\n\nReturn JSON only:")
    ])
    
    try:
        from langchain_core.output_parsers import JsonOutputParser
        parser = JsonOutputParser()
        chain = filter_prompt | llm | parser
        filters = chain.invoke({"question": query})
        return filters
    except:
        return {}

def filter_docs_by_metadata(docs, filters: dict):
    """ì¶”ì¶œëœ í•„í„°ë¡œ ë¬¸ì„œ í•„í„°ë§"""
    if not filters:
        return docs
    
    filtered = docs
    
    # ì •í™•í•œ ë‚ ì§œ ë§¤ì¹­
    if filters.get("date_exact"):
        target_date = filters["date_exact"]
        filtered = [d for d in filtered if target_date in d.metadata.get("date", "")]
    
    # ì›” ë²”ìœ„ ë§¤ì¹­ (e.g., 2021-07)
    elif filters.get("date_month"):
        target_month = filters["date_month"]
        filtered = [d for d in filtered if target_month in d.metadata.get("date", "")]
    
    # ì—°ë„ ë§¤ì¹­
    elif filters.get("date_year"):
        target_year = filters["date_year"]
        filtered = [d for d in filtered if target_year in d.metadata.get("date", "")]
    
    # ë°œì‹ ìž ë§¤ì¹­ (ì´ë¦„ ë˜ëŠ” ì´ë©”ì¼)
    if filters.get("sender_name"):
        sender_name = filters["sender_name"].lower()
        filtered = [d for d in filtered 
                   if sender_name in d.metadata.get("sender", "").lower()]
    
    return filtered

# =====================
# 4. Document Formatting
# =====================
def format_docs(docs):
    """ë¬¸ì„œë¥¼ ë¬¸ìžì—´ë¡œ í¬ë§·íŒ… - ë©”íƒ€ë°ì´í„° ê°•ì¡°ë¡œ ë‚ ì§œ/ë°œì‹ ìž ê¸°ë°˜ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ"""
    formatted = []
    for i, doc in enumerate(docs, 1):
        meta = doc.metadata
        sender = meta.get('sender', 'Unknown')
        recipients = meta.get('recipients', 'Unknown')
        date = meta.get('date', 'Unknown')
        attachments = meta.get('attachments', [])
        content = doc.page_content
        
        # ì²¨ë¶€íŒŒì¼ í¬ë§·íŒ…
        attachments_str = ', '.join(attachments) if attachments else 'None'
        
        formatted.append(
            f"========== EMAIL {i} ==========\n"
            f"ðŸ“… DATE: {date}\n"
            f"ðŸ‘¤ FROM: {sender}\n"
            f"ðŸ‘¥ TO: {recipients}\n"
            f"ðŸ“Ž ATTACHMENTS: {attachments_str}\n"
            f"ðŸ“§ CONTENT:\n{content}\n"
            f"================================"
        )
    return "\n\n".join(formatted)

prompt = ChatPromptTemplate.from_messages([
    ("system",
     "You are a helpful assistant specialized in ITER project email communications.\n"
     "You have access to email archives from the ITER Vacuum Vessel project.\n\n"
     "IMPORTANT INSTRUCTIONS:\n"
     "1. Use the provided email context to answer questions about:\n"
     "   - VV (Vacuum Vessel) components and procedures\n"
     "   - Transportation and logistics\n"
     "   - ANB reports and inspections\n"
     "   - Meeting schedules and discussions\n"
     "   - Technical documentation\n\n"
     "2. If the context contains relevant information, cite it in your answer.\n"
     "3. For conceptual questions about ITER/fusion, combine the email context with your knowledge.\n"
     "4. If no relevant emails are found, say so clearly.\n"
     "5. When discussing email threads, describe the conversation flow.\n"
     "6. Be specific about dates, people, and technical details when available.\n\n"
     "âš ï¸ CRITICAL FOR DATE/METADATA-BASED QUERIES:\n"
     "- Pay CLOSE ATTENTION to the ðŸ“… DATE field in each email\n"
     "- When asked about specific dates, filter emails by matching the DATE exactly\n"
     "- Check ðŸ“Ž ATTACHMENTS when asked about files or documents\n"
     "- Use ðŸ‘¤ FROM and ðŸ‘¥ TO fields for sender/recipient questions\n"
     "- List ALL matching emails when asked about a specific date or person\n"
     "- Format dates clearly (e.g., 'January 31, 2021' or '2021-01-31')\n"),
    ("human", "Question: {question}\n\nRelevant Emails:\n{context}")
])

# =====================
# 5. Smart Retrieval Function
# =====================
def smart_retrieve(query: str):
    """ì¿¼ë¦¬ ë¶„ì„ + ë©”íƒ€ë°ì´í„° í•„í„°ë§(ì„ í–‰) + ì˜ë¯¸ ê²€ìƒ‰ì„ ê²°í•©í•œ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰"""
    # 1ë‹¨ê³„: LLMìœ¼ë¡œ ì¿¼ë¦¬ ë¶„ì„
    filters = extract_query_filters(query, llm)
    
    # 2ë‹¨ê³„: ChromaDB where ì ˆ êµ¬ì„± (ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì„ í–‰)
    where_filter = None
    if filters and any(filters.values()):
        where_conditions = []
        
        # ë‚ ì§œ í•„í„°ë§
        if filters.get("date_exact"):
            where_conditions.append({"date": {"$contains": filters["date_exact"]}})
        elif filters.get("date_month"):
            where_conditions.append({"date": {"$contains": filters["date_month"]}})
        elif filters.get("date_year"):
            where_conditions.append({"date": {"$contains": filters["date_year"]}})
        
        # ë°œì‹ ìž í•„í„°ë§
        if filters.get("sender_name"):
            where_conditions.append({"sender": {"$contains": filters["sender_name"]}})
        
        # ì—¬ëŸ¬ ì¡°ê±´ì´ ìžˆìœ¼ë©´ AND ì—°ì‚°
        if len(where_conditions) > 1:
            where_filter = {"$and": where_conditions}
        elif len(where_conditions) == 1:
            where_filter = where_conditions[0]
    
    # 3ë‹¨ê³„: ë©”íƒ€ë°ì´í„° í•„í„°ë§ í›„ ìœ ì‚¬ë„ ê²€ìƒ‰ (k=10)
    try:
        if where_filter:
            # ë©”íƒ€ë°ì´í„° í•„í„°ë§ì„ ë¨¼ì € ì ìš©í•œ ê²€ìƒ‰
            candidates = vectorstore.similarity_search(query, k=10, filter=where_filter)
        else:
            # í•„í„° ì—†ìœ¼ë©´ ì¼ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
            candidates = vectorstore.similarity_search(query, k=10)
    except Exception as e:
        # í•„í„°ë§ ì‹¤íŒ¨ì‹œ í´ë°±
        print(f"Filtered search failed: {e}, falling back to normal search")
        candidates = vectorstore.similarity_search(query, k=10)
    
    return candidates

# =====================
# 6. LLM and Chain
# =====================
llm = ChatOpenAI(model="gpt-4o", temperature=0)

rag_chain = (
    {
        "context": lambda x: format_docs(smart_retrieve(x)),
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
    | StrOutputParser()
)

# =====================
# 5. Chat UI with History
# =====================

# ì‚¬ì´ë“œë°”ì— Clear Chat ë²„íŠ¼ ì¶”ê°€
with st.sidebar:
    st.markdown("### ðŸ’¬ Chat Controls")
    if st.button("ðŸ—‘ï¸ Clear Chat History", use_container_width=True):
        st.session_state.messages = []
        st.session_state.source_docs = {}
        st.rerun()
    
    st.markdown("---")
    st.markdown("### ðŸ“Š Chat Statistics")
    st.metric("Total Messages", len(st.session_state.messages))
    st.metric("Q&A Pairs", len(st.session_state.messages) // 2)

# ì±„íŒ… ë©”ì‹œì§€ ížˆìŠ¤í† ë¦¬ í‘œì‹œ
chat_container = st.container()
with chat_container:
    # ì²« ë°©ë¬¸ ì‹œ í™˜ì˜ ë©”ì‹œì§€ í‘œì‹œ
    if len(st.session_state.messages) == 0:
        with st.chat_message("assistant"):
            st.markdown("""
            ðŸ‘‹ **Welcome to ITER Outlook RAG Chatbot!**
            
            Try asking me anything! ðŸ’¬
            """)
    
    # ì´ì „ ëŒ€í™” ë‚´ì—­ í‘œì‹œ
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Assistant ë©”ì‹œì§€ì— ì¶œì²˜ ë¬¸ì„œ í‘œì‹œ
            if message["role"] == "assistant" and idx in st.session_state.source_docs:
                with st.expander("ðŸ“Ž View Source Emails"):
                    docs = st.session_state.source_docs[idx]
                    for i, doc in enumerate(docs, 1):
                        meta = doc.metadata
                        title = meta.get("subject_preview", "(No Subject)")
                        sender = meta.get("sender", "(Unknown Sender)")
                        recipients = meta.get("recipients", "(Unknown Recipients)")
                        date = meta.get("date", "(Unknown Date)")
                        content = doc.page_content
                        
                        st.markdown(f"**ðŸ“§ Email {i}**")
                        st.markdown(f"**From:** `{sender}`")
                        st.markdown(f"**To:** `{recipients}`")
                        st.markdown(f"**Date:** `{date}`")
                        st.markdown(f"**Subject:** {title}")
                        
                        # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                        with st.expander(f"ðŸ“„ View Email Content"):
                            st.text(content[:800] + ('...' if len(content) > 800 else ''))
                        
                        if i < len(docs):
                            st.markdown("---")

# ì±„íŒ… ìž…ë ¥ì°½ (í™”ë©´ í•˜ë‹¨ ê³ ì •)
if prompt := st.chat_input("ðŸ’¬ Ask about ITER emails... (e.g., What are VV transportation challenges?)"):
    # ì‚¬ìš©ìž ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # ì‚¬ìš©ìž ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Assistant ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ðŸ” Searching emails and generating answer..."):
            # ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ (ì¿¼ë¦¬ ë¶„ì„ + ë©”íƒ€ë°ì´í„° í•„í„°ë§ + ì˜ë¯¸ ê²€ìƒ‰)
            docs = smart_retrieve(prompt)
            
            # ë‹µë³€ ìƒì„±
            answer = rag_chain.invoke(prompt)
            
            # ë‹µë³€ í‘œì‹œ
            st.markdown(answer)
            
            # í˜„ìž¬ assistant ë©”ì‹œì§€ ì¸ë±ìŠ¤
            assistant_idx = len(st.session_state.messages)
            
            # ì¶œì²˜ ë¬¸ì„œ í‘œì‹œ
            with st.expander("ðŸ“Ž View Source Emails"):
                for i, doc in enumerate(docs, 1):
                    meta = doc.metadata
                    title = meta.get("subject_preview", "(No Subject)")
                    sender = meta.get("sender", "(Unknown Sender)")
                    recipients = meta.get("recipients", "(Unknown Recipients)")
                    date = meta.get("date", "(Unknown Date)")
                    content = doc.page_content
                    
                    st.markdown(f"**ðŸ“§ Email {i}**")
                    st.markdown(f"**From:** `{sender}`")
                    st.markdown(f"**To:** `{recipients}`")
                    st.markdown(f"**Date:** `{date}`")
                    st.markdown(f"**Subject:** {title}")
                    
                    # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                    with st.expander(f"ðŸ“„ View Email Content"):
                        st.text(content[:800] + ('...' if len(content) > 800 else ''))
                    
                    if i < len(docs):
                        st.markdown("---")
            
            # Assistant ë©”ì‹œì§€ì™€ ì¶œì²˜ ë¬¸ì„œ ì €ìž¥
            st.session_state.messages.append({"role": "assistant", "content": answer})
            st.session_state.source_docs[assistant_idx] = docs